# 3DGS与DepthSplat的技术路线对比
## 3DGS的技术路线
![输入图片说明](/imgs/2025-10-29/WxEVOjszwlLIeMw4.png)
### 一、初始化
**输入Sfm点云**，在每个点云的位置创建3D高斯，得到每个高斯点的高斯参数。
### 二、迭代（核心）
将3DGS投影到二维平面，累积每个像素的高斯贡献，得到渲染图像；再带入损失函数，反向传播对每个高斯参数的偏导，引入**自适应密度控制**，
（自适应密度控制如下：
• 克隆: 梯度大的高斯 → 分裂
• 剪枝: 不透明度低 → 删除 
• 致密化: 欠重建区域 → 增加高斯）
每100次迭代增删一次透明度低的高斯
## DepthSplat的技术路线
![输入图片说明](/imgs/2025-10-30/9G0aN5JZVFiQhNnx.png)
**输入多视角图像**，分为并行的双分支特征提取（多视图分支、单目分支）
### 多视图分支
在 Multi-View Transformer 步骤输出多视图感知特征（$F_i$）；在 Cost Volume 步骤经过假设每个视图的$F_i$采样深度、特征扭曲、计算相关性，最终把所有$d_m$的相关性堆叠到一个**代价体$C_i$** ，形状是（$\frac{H}{s} × \frac{W}{s} × D$）。
### 单目分支
利用 Depth Anything V2 模型，提取其中的 Vision Transformer 骨干，简单地对单目特征的空间分辨率进行双线性插值，得到与前文的代价体体积相同的**单目特征 $F_i^{mono}$**
### 特征融合
直接串联 $C_i$ 和 $F_i^{mono}$ ，在2D U-Net的操作如下：对每张图像输出一个形状为$\frac{H}{s} × \frac{W}{s} × D$的张量，用 softmax 操作归一化 $D$ 维度，并对所有深度候选进行加权平均以**输出深度图。**
### 生成3D高斯
输入深度图和相机的参数，反投影得到3D高斯的位置中心 μ ；再引入DPT头，输入图像、深度、特征，输出颜色 c ，不透明度 α ，协方差 Σ 。得到最终的3D Gaussians。
之后就是常规的渲染并计算损失。
## 对比
|方面|3DGS  |DepthSplat|
|--|--|--|
| 输入 | SfM点云 | 多视角图像 |
| 过程 | 先生成3D高斯，再迭代优化 | 先从多视角图像预测深度，再生成 3D 高斯 |
| 优化思路 | 显式优化（从零开始学习） | 深度估计生成隐式几何结构（利用预训练） |
| 损失函数 | 光度：MSE + LPIPS | 光度：MSE+LPIPS 和深度：L1Loss + 梯度损失 |
| 鲁棒性 | 在困难场景容易出错 | 利用单目先验，鲁棒性好 |

